{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import re\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatization\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load sentiment dict\n",
    "df_anger = pd.read_csv(\"/Users/huaxinjin/Desktop/sentiment dict/anger-scores.csv\")\n",
    "anger_score={}\n",
    "df_anticipation = pd.read_csv(\"/Users/huaxinjin/Desktop/sentiment dict/anticipation-scores.csv\")\n",
    "anticipation_score={}\n",
    "df_disgust = pd.read_csv(\"/Users/huaxinjin/Desktop/sentiment dict/disgust-scores.csv\")\n",
    "disgust_score={}\n",
    "df_fear = pd.read_csv(\"/Users/huaxinjin/Desktop/sentiment dict/fear-scores.csv\")\n",
    "fear_score={}\n",
    "df_joy = pd.read_csv(\"/Users/huaxinjin/Desktop/sentiment dict/joy-scores.csv\")\n",
    "joy_score={}\n",
    "df_sadness = pd.read_csv(\"/Users/huaxinjin/Desktop/sentiment dict/sadness-scores.csv\")\n",
    "sadness_score={}\n",
    "df_surprise = pd.read_csv(\"/Users/huaxinjin/Desktop/sentiment dict/surprise-scores.csv\")\n",
    "surprise_score={}\n",
    "df_trust = pd.read_csv(\"/Users/huaxinjin/Desktop/sentiment dict/trust-scores.csv\")\n",
    "trust_score={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_dict(csv, senti_dict):\n",
    "    for index in range(len(csv)):\n",
    "        tokens = [csv['word'][index]]\n",
    "        tagged_sent = pos_tag(tokens)\n",
    "        wnl = WordNetLemmatizer()\n",
    "        wordnet_pos = get_wordnet_pos(tagged_sent[0][1]) or wordnet.NOUN\n",
    "        word=wnl.lemmatize(tagged_sent[0][0], pos=wordnet_pos)\n",
    "        word = word.lower()\n",
    "        senti_dict[word]= csv['score'][index]\n",
    "        senti_dict[csv['word'][index]]= csv['score'][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dict(df_anger,anger_score)\n",
    "complete_dict(df_anticipation,anticipation_score)\n",
    "complete_dict(df_disgust,disgust_score)\n",
    "complete_dict(df_fear,fear_score)\n",
    "complete_dict(df_joy,joy_score)\n",
    "complete_dict(df_sadness,sadness_score)\n",
    "complete_dict(df_surprise,surprise_score)\n",
    "complete_dict(df_trust,trust_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine=create_engine('postgresql+psycopg2://postgres:6969@localhost/170final')\n",
    "\n",
    "df = pd.read_sql_query('SELECT * from reddit_comments order by comment_created_time',con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = pd.read_sql_query(\"SELECT distinct(comment_created_time) from reddit_comments order by comment_created_time\",con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['scare_index']=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##term frequency\n",
    "def term_frequency(l):\n",
    "    tf_dict={}\n",
    "    for index in range(len(l)):\n",
    "        line = l[index]\n",
    "        tokens = word_tokenize(line) \n",
    "        tagged_sent = pos_tag(tokens) #form:[('football', 'NN'), ('is', 'VBZ')\n",
    "        for k in range(len(tokens)):\n",
    "            wnl = WordNetLemmatizer()\n",
    "            wordnet_pos = get_wordnet_pos(tagged_sent[k][1]) or wordnet.NOUN\n",
    "            word=wnl.lemmatize(tagged_sent[k][0], pos=wordnet_pos)\n",
    "            word = word.lower()\n",
    "            if word.isalpha() and len(word)>2 and word not in set(stopwords.words('english')):\n",
    "                if word in tf_dict:\n",
    "                    tf_dict[word]+=1\n",
    "                else:\n",
    "                    tf_dict[word]=1\n",
    "    return tf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#score for different sentiment\n",
    "##other: num of comments that are neutrality\n",
    "def sentiments_score(tf_dict):\n",
    "    s= {\"anger\":0, \"anticipation\":0,  \"disgust\":0, \"fear\":0, \"joy\":0, \"sadness\":0, \"surprise\":0, \"trust\":0,\"other\":0}\n",
    "    other=True\n",
    "    for k,v in tf_dict.items():\n",
    "        if k in anger_score:\n",
    "            s[\"anger\"]+= v * anger_score[k]\n",
    "            other = False\n",
    "        if k in anticipation_score:\n",
    "            s[\"anticipation\"]+= v * anticipation_score[k]\n",
    "            other = False\n",
    "        if k in disgust_score:\n",
    "            s[\"disgust\"]+= v * disgust_score[k]\n",
    "            other = False\n",
    "        if k in fear_score:\n",
    "            s[\"fear\"]+= v * fear_score[k]\n",
    "            other = False\n",
    "        if k in joy_score:\n",
    "            s[\"joy\"]+= v * joy_score[k]\n",
    "            other = False\n",
    "        if k in sadness_score:\n",
    "            s[\"sadness\"]+= v * sadness_score[k]\n",
    "            other = False\n",
    "        if k in surprise_score:\n",
    "            s[\"surprise\"]+= v * surprise_score[k]\n",
    "            other = False\n",
    "        if k in trust_score:\n",
    "            s[\"trust\"]+= v * trust_score[k]\n",
    "            other = False\n",
    "        if other:\n",
    "            s[\"other\"]+=1\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-3703f4a0414f>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['scare_index'][k]=scare_index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12503883359742304\n",
      "2020-06-02\n",
      "0.14440991121544375\n",
      "2020-06-03\n",
      "0.1428349155675567\n",
      "2020-06-04\n",
      "0.13957883867056559\n",
      "2020-06-05\n",
      "0.1532035178930934\n",
      "2020-06-06\n",
      "0.16672832585335914\n",
      "2020-06-07\n",
      "0.16638987063824823\n",
      "2020-06-08\n",
      "0.14614676918351077\n",
      "2020-06-09\n"
     ]
    }
   ],
   "source": [
    "for d in date[\"comment_created_time\"]:\n",
    "    print(d)\n",
    "    daily_comments_list=[]\n",
    "    temp=df[df['comment_created_time']==d]\n",
    "    #temp[\"body_text\"]=temp[\"body_text\"].str.replace('\"',\"'\",regex=False)\n",
    "    temp.head()\n",
    "    for k in temp.index.values:\n",
    "        daily_comments_list.append(temp[\"body_text\"][k])\n",
    "    comments_num = len(daily_comments_list)\n",
    "    f=term_frequency(daily_comments_list)\n",
    "    s= sentiments_score(f)\n",
    "    if s[\"fear\"]!=0:\n",
    "        proportion = s[\"fear\"] / (sum(s.values())- s[\"other\"])\n",
    "        scare_comments_num = proportion * ( comments_num - s[\"other\"])\n",
    "        scare_index= scare_comments_num/comments_num\n",
    "        for k in temp.index.values:\n",
    "            df['scare_index'][k]=scare_index\n",
    "        print(scare_index)\n",
    "    else:\n",
    "        print(\"can't define\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"May05.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "national = pd.read_csv(\"/Users/huaxinjin/Desktop/170final/national-history.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "national[\"death_rate\"]=national[\"death\"]/national[\"positive\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"May05.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1[[\"comment_created_time\",\"scare_index\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop_duplicates()\n",
    "df2.comment_created_time = pd.to_datetime(df2.comment_created_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "national.date = pd.to_datetime(national.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.merge(national, df2, left_on = 'date', right_on = 'comment_created_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the result of this code is output as combined_index.csv\n",
    "df3.to_csv(\"combined_index.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
